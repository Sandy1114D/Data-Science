{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1. What are the advantages of a CNN over a fully connected DNN for image classification?\n",
        "2. Consider a CNN composed of three convolutional layers, each with 3 × 3 kernels, a stride of\n",
        "2, and &quot;same&quot; padding. The lowest layer outputs 100 feature maps, the middle one outputs\n",
        "200, and the top one outputs 400. The input images are RGB images of 200 × 300 pixels.\n",
        "What is the total number of parameters in the CNN? If we are using 32-bit floats, at least how much\n",
        "RAM will this network require when making a prediction for a single instance? What about when\n",
        "training on a mini-batch of 50 images?\n",
        "3. If your GPU runs out of memory while training a CNN, what are five things you could try to\n",
        "solve the problem?\n",
        "4. Why would you want to add a max pooling layer rather than a convolutional layer with the\n",
        "same stride?\n",
        "5. When would you want to add a local response normalization layer?\n",
        "6. Can you name the main innovations in AlexNet, compared to LeNet-5? What about the main\n",
        "innovations in GoogLeNet, ResNet, SENet, and Xception?\n",
        "7. What is a fully convolutional network? How can you convert a dense layer into a\n",
        "convolutional layer?\n",
        "8. What is the main technical difficulty of semantic segmentation?\n",
        "9. Build your own CNN from scratch and try to achieve the highest possible accuracy on MNIST.\n",
        "10. Use transfer learning for large image classification, going through these steps:\n",
        "a. Create a training set containing at least 100 images per class. For example, you could\n",
        "classify your own pictures based on the location (beach, mountain, city, etc.), or\n",
        "alternatively you can use an existing dataset (e.g., from TensorFlow Datasets).\n",
        "b. Split it into a training set, a validation set, and a test set.\n",
        "c. Build the input pipeline, including the appropriate preprocessing operations, and\n",
        "optionally add data augmentation.\n",
        "d. Fine-tune a pretrained model on this dataset."
      ],
      "metadata": {
        "id": "4eG4sHt88A9i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **ANS OFA ABOVE QUESTIONS ARE AS FOLLOW**"
      ],
      "metadata": {
        "id": "SBoTJIjF8HrA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. The main advantages of a CNN over a fully connected DNN for image classification are that a CNN is able to exploit the spatial structure of the input data, which is particularly useful for images, and it can learn hierarchical features automatically, which reduces the number of parameters required and improves generalization.\n",
        "\n",
        "2. The total number of parameters in the CNN is (3x3x3+1)x100 + (3x3x100+1)x200 + (3x3x200+1)x400 = 1,664,400. When making a prediction for a single instance, the network will require at least 200x300x3x32 + 1,664,400x32 = 20.9 MB of RAM. When training on a mini-batch of 50 images, the network will require at least 50x200x300x3x32 + 1,664,400x32 = 1.6 GB of RAM.\n",
        "\n",
        "3. Five things you could try to solve the problem of running out of GPU memory while training a CNN are:\n",
        "\n",
        "- Reduce the batch size\n",
        "- Reduce the size of the images\n",
        "- Reduce the depth or width of the network\n",
        "- Use mixed precision training\n",
        "- Use gradient checkpointing\n",
        "\n",
        "4. Adding a max pooling layer rather than a convolutional layer with the same stride reduces the spatial resolution of the feature maps, which can be useful to reduce the number of parameters and improve generalization, by making the network more robust to small translations and distortions in the input.\n",
        "\n",
        "5. A local response normalization layer can be useful to enhance the contrast between neighboring feature maps and promote competition between feature maps, which can improve generalization and reduce overfitting.\n",
        "\n",
        "6. The main innovations in AlexNet, compared to LeNet-5, are:\n",
        "- The use of ReLU activation functions, which accelerate convergence and reduce overfitting.\n",
        "- The use of dropout regularization, which reduces overfitting.\n",
        "- The use of data augmentation, which increases the effective size of the training set.\n",
        "- The use of GPU acceleration, which speeds up training.\n",
        "- The use of a larger network with more layers and more filters, which increases the representational power of the model.\n",
        "\n",
        "The main innovations in GoogLeNet are:\n",
        "- The use of an Inception module, which allows the network to learn both spatial features and channel-wise features at different scales, while minimizing the number of parameters.\n",
        "- The use of global average pooling instead of fully connected layers, which reduces the number of parameters and avoids overfitting.\n",
        "- The use of auxiliary classifiers, which provide additional supervision to the network and improve the gradient flow during training.\n",
        "\n",
        "The main innovation in ResNet is the use of residual connections, which allow the network to learn residual functions instead of direct mappings, and make it easier to train very deep networks.\n",
        "\n",
        "The main innovation in SENet is the use of a squeeze-and-excitation module, which allows the network to learn channel-wise feature re-calibration weights, and improve the representational power of the model.\n",
        "\n",
        "The main innovation in Xception is the use of depthwise separable convolutions, which split the standard convolution into a depthwise convolution and a pointwise convolution, and reduce the number of parameters and computation required.\n",
        "\n",
        "7. A fully convolutional network is a network that only uses convolutional layers and does not have any fully connected layers. To convert a dense layer into a convolutional layer, you can use a 1x1 convolution with the same number of filters as the number of neurons in the dense layer.\n",
        "\n",
        "8. The main technical difficulty of semantic segmentation is the need to preserve the spatial resolution of the feature maps while reducing their size, in order to produce a dense pixel-level output. This requires the use of skip connections,"
      ],
      "metadata": {
        "id": "_vQe-D_Y8N5B"
      }
    }
  ]
}